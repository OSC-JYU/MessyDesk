
TODO

- NER objects to search
- user management OK (initial, no research groups yet)

- sets
-- Set crunhers implementation
-- Set view must have pager and it must use smaller thumbnails


- Image ROI's extract must be dynamic! If extracted image is crunched, then ROI gets locked

- PDF image rendering in smaller chunks (more user friendly. One must get page count first.)

- human.json to ROI records



- change type of json outputs to "json" and extension specifies more specfic type like ".osd.json" or ".ner.json"
- thumbnails must not be greater than original image (ROI)

- Nextcloud import


- OSD_rotate now creates a identical copy of original file. Change so that only File node is created and path points to origina path.
  - make sure that removing the new File node does not remove the original file

- virtual crunchers (tesseract orientation detection + imaginary rotate = fix orientation)
- process report file


UI TODO
- create set must focus on new Set
- uploading file to set must show that file is loaded



MAYBE:
- change thumbnail generation from Imaginary to python thumbnailer (not urgent)
- IIIF server (for image ROIs)


DONE
- indexing queue (for indexing and removing from index) OK
- SOLR OK
- ner.json to ROI records (with type Person/Organisation/Place/Date) OK
- image dimensions for all images (queue call, 2024.09.23)
- Cruncher that uses that JSON as input (auto-rotate)
- orientation detection must output JSON
- text file description from text content OK
- implement sets
- crunchers creator as pop up (does not mess graph)





ArcadeDB:

 docker run --rm -p 2480:2480 -p 2424:2424 -v messydesk_arcade:/home/arcadedb/databases  -e JAVA_OPTS="-Darcadedb.server.rootPassword=node_master" arcadedata/arcadedb:23.7.1


adding users:
curl -X POST http://localhost:2480/api/v1/server        -d '{ "command": "create user { \"name\": \"messydesk_user\", \"password\": \"MD_USER_PASSWORD\", \"databases\": { \"messydesk\": \"admin\"} }" }'        -H "Content-Type: application/json"        --user root:PASSWORD


NATS:

start with monitoring and jetstreams enabled:

  docker run -d --name nats-main -p 4222:4222 -p 6222:6222 -p 8222:8222 nats -js -m 8222


monitoring:
http://localhost:8222/jsz?consumers=true


NOMAD:

  sudo nomad agent -dev  

monitoring:
http://localhost:4646/ui/jobs

docker version for local development:
https://github.com/multani/docker-nomad



NOMAD + podman
https://support.hashicorp.com/hc/en-us/articles/20752437319955-Configuring-nomad-podman-driver-with-a-Nomad-Cluster-and-Running-a-Nomad-Job-Using-the-Podman-Driver


podman unix socket must be activated: /run/podman/podman.sock
https://github.com/containers/podman/blob/main/docs/tutorials/socket_activation.md

It's good idea to change logging level to "warn"
 sudo vim /usr/lib/systemd/system/podman.service 

[Service]
Environment=LOGGING="--log-level=warn"

Then start it:

sudo systemctl start podman.socket



/etc/nomad.d/nomad.hcl

server {
  # license_path is required for Nomad Enterprise as of Nomad v1.1.1+
  #license_path = "/etc/nomad.d/license.hclic"
  enabled          = true
  bootstrap_expect = 1
}

client {
  enabled = true
  servers = ["127.0.0.1"]
  options = {
    "driver.denylist" = "docker"
  }
}
plugin "nomad-driver-podman" {
  config {
    volumes {
      enabled      = true
      selinuxlabel = "z"
    }
  }
}




sudo nomad agent -dev -plugin-dir=/opt/nomad/plugins -config=/etc/nomad.d


check podman driver:
nomad node status
nomad node status <nomad_client_node_id> | grep -i "Driver status"
nomad node status -verbose <nomad_client_node_id> | grep -i "podman"


Container reposiotry authentication in services .hcl:

            auth {
              username = ""
              password = ""
            }



CONTAINER PORTS (when running locally):

MD-poppler            8300
MD-tesseract          8400
MD-pdfalto            8500
MD-finbert-ner        8600
MD-human              8700
MD-paddle-ocr-fin     8800
MD-imaginary          9000
  

http --form POST :9000/thumbnail file@OK_Kiviaho_Pekka.pdf width=200


INTERNAL API:

start backend with different database and data dir:
MODE=development DB_PASSWORD=node_master DB_NAME=md_test DATA_DIR=test nodemon index.js

modify and and internal.js (in 'test' directory so that data dir is created under 'test'):
MODE=development DB_PASSWORD=node_master DB_NAME=md_test node internal.js


*************************************************************************
SOLR:

  docker run -p 8983:8983 -t solr

add core:

  solr create_core -c messydesk

remove all docs:

  curl http://localhost:8983/solr/messydesk/update?commit=true -d '<delete><query>*:*</query></delete>'

query:

  curl "http://localhost:8983/solr/messydesk/query" -d '
  {
    params: {
      q: "kuhasalo",defType: "edismax", qf: "fulltext^5", pf:"fulltext^5", fq: "owner:tupsu@v.com", wt: "json"
    }
  }'

Set configs via API

- add field

  curl -X POST -H 'Content-Type: application/json' -d '{"add-field": {
    "name":"text",
    "type":"string",
    "stored":true,
    "indexed":true
  }
  }' "http://localhost:8983/solr/messydesk/schema"


- add copyField

  curl -X POST -H 'Content-Type: application/json' -d '{"add-copy-field": {"source":"*_str", "dest":"text"}}' "http://localhost:8983/solr/messydesk/schema"


- delete copyField
  curl -X POST -H 'Content-Type: application/json' \   -d '{
    "delete-copy-field": {
      "source": "*_str",
      "dest": "text"                                          
    }
  }' \
  "http://localhost:8983/solr/messydesk/schema"


- remove field:
  curl -X POST -H 'Content-Type: application/json' \
  -d '{"delete-field":{"name":"text"}}'

- replace field:

  curl -X POST -H 'Content-Type: application/json' \
  -d '{
    "replace-field": {
      "name":"fulltext",
      "type":"text_edge_ngram",
      "stored":true,
      "indexed":true
    }
  }' \
  "http://localhost:8983/solr/messydesk/schema"


- delete index:

  curl -X POST -H 'Content-Type: application/json' \
  -d '{ "delete": { "query": "*:*" } }' \
  "http://localhost:8983/solr/YOUR_CORE/update?commit=true"


- n-gram settings (avoid need for wildcards):
curl -X POST -H 'Content-type:application/json' \
  http://localhost:8983/solr/<your-core-name>/schema \
  --data-binary '{
    "add-field-type": {
      "name": "text_edge_ngram",
      "class": "solr.TextField",
      "positionIncrementGap": "100",
      "analyzer": {
        "tokenizer": { "class": "solr.StandardTokenizerFactory" },
        "filters": [
          { "class": "solr.LowerCaseFilterFactory" },
          { "class": "solr.EdgeNGramFilterFactory", "minGramSize": "3", "maxGramSize": "20" }
        ]
      }
    }
  }'



schema + copyFields:
- node (string) // Arcadadb @type
- type (string)  // image, text, ner.json...
- owner (string)
- description (text_general) -> text
- label (string) -> text
- fulltext (text_general) -> text
- text (text_edge_ngram)
- error_node (string)
- error (string)




https://solr.apache.org/guide/6_6/the-extended-dismax-query-parser.html

************************** SOLR ends ************************************

PDF to other format:
- In what format should be used displaying and indexing of PDF files? User should get PDF indexed just by uploading it (if - of course- it has text in it)

- alternatives:
-- pure html
https://github.com/pdf2htmlEX/pdf2htmlEX
build from: https://github.com/sergiomtzlosa/docker-pdf2htmlex
* change git:// to https:// in Dockerfile
podman build -t pdf2htmlex .
podman run -it localhost/pdf2htmlex

pdf2htmlEX --zoom 1.3 43901.pdf 43901.html

-- HOCR html
https://github.com/HazyResearch/pdftotree
-- Alto XML
https://github.com/kermitt2/pdfalto
-- page XML
OCR: https://github.com/mauvilsa/tesseract-recognize



TESTING WITH NGINX
- ensure that URL paths are working

    location /md {
        rewrite ^/md/(.*)$ /$1 break;
        proxy_pass http://localhost:8200;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;

        # Optional: Allow WebSocket support
        proxy_http_version 1.1;
        proxy_set_header Upgrade $http_upgrade;
        proxy_set_header Connection "upgrade";
    }

        error_page 404 /404.html;
        location = /404.html {
        }

        error_page 500 502 503 504 /50x.html;
        location = /50x.html {
        }
    }


sudo setsebool -P httpd_can_network_connect 1


MISC:


graph alternative:
https://github.com/jagenjo/litegraph.js/







CRUNCHES suggestions:


https://demo.verapdf.org/

https://github.com/mattiasw/ExifReader

img2table: https://github.com/xavctn/img2table
  - html export: https://github.com/xavctn/img2table/issues/92



line removal: 
https://stackoverflow.com/questions/33949831/how-to-remove-all-lines-and-borders-in-an-image-while-keeping-text-programmatica

convert input.jpg                           \
-type Grayscale                             \
-negate                                     \
-define morphology:compose=darken           \
-morphology Thinning 'Rectangle:1x30+0+0<'  \
-negate                                     \
converted_image.jpg



https://deepdoctection.readthedocs.io/en/latest/tutorials/get_started_notebook/

NER:
https://medium.com/quantrium-tech/top-3-packages-for-named-entity-recognition-e9e14f6f0a2a

Kansalliskirjasto: nimientiteettien tunnistus:
https://www.doria.fi/bitstream/handle/10024/187816/Nimientiteettien%20tunnistus.20230830.pdf?sequence=1&isAllowed=y

https://github.com/DALAI-project/NER_API


GREY LITERATURE METADATA EXTRACTION:
https://www.doria.fi/bitstream/handle/10024/188075/Tekoa%cc%88lykahvit_%20Extracting%20metadata%20using%20LLMs.pdf?sequence=1&isAllowed=y


OCR:
https://github.com/mindee/doctr
mitä kieliä tukee?
https://github.com/mindee/doctr/discussions/837

https://medium.com/quantrium-tech/text-extraction-using-doctr-ocr-471e417764d5


https://github.com/rescribe

HOCR:
https://github.com/ocropus/hocr-tools

Layout analysis:
https://dhlab-epfl.github.io/dhSegment/
https://pypi.org/project/doc-ufcn/


dewarp:
https://github.com/lmmx/page-dewarp

deskew:
https://github.com/sbrunner/deskew
https://github.com/kakul/Alyn

denoising:
https://stackoverflow.com/questions/49318622/denoising-binary-image-in-python

https://github.com/Leedeng/SauvolaNet

https://stackoverflow.com/questions/62042172/how-to-remove-noise-in-image-opencv-python


Image annotation:
https://www.robots.ox.ac.uk/~vgg/software/via/via.html

Image duplicates or similar:
https://github.com/dsys/match
https://github.com/rhsimplex/image-match
http://www.phash.org/

pytorch container:
docker run --rm -ti --ipc=host pytorch/pytorch:latest

from transformers import pipeline

pipe = pipeline("token-classification", model="Kansallisarkisto/finbert-ner")
tulos = pipe('Kyllösen vanhempi poika Erkki oli kova mies')
print(tulos)





SQL:
MATCH {type: Project, as: project}-HAS_FILE->
{type:File, as: file, where:(set IS NULL)} RETURN project,file


MATCH {as:project, type:Project, where: (@rid=#217:15)}-->{as:file, 
where:((@type = 'Set' OR @type = 'SetProcess' OR @type = 'Process')
       OR ( @type = 'File'  AND (set is NULL OR expand = true) )), while: (true)}
       
return project, file


MISC:
https://language-data-space.ec.europa.eu/related-initiatives/alt-edic_en

https://github.com/xamkfi/digitalia-aida-pdf-paddleocr

https://huggingface.co/docs/transformers/model_doc/trocr





asciiflow.com


                                           +--------> EXPANDED FILE
                                           |                       
                                           |                       
              +-------->PROCESS---------->SET                      
              |                                                    
    +---> FILE|                                                    
    |         |                                                    
    |         +------->PROCESS----------> FILE-----> PROCESS       
    |                                                              
    |                                                              
    |                                                              
PROJECT                                                            
    |                                                              
    |                                                              
    |                                                              
    +--> SET----------> PROCESS -------> SET                   



REST examples

- add Desk
http POST :8200/api/projects label=rest-Desk

- add file to Desk

